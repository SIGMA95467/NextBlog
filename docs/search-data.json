[
    
    
    
        
            {
                "id": 0,
                "href": "https://sigma95467.github.io/NextBlog/about/",
                "title": "About",
                "section": "",
                "date" : "2022.03.30",
                "body": "自学图形学中……\n"
            }
    
        ,
            {
                "id": 1,
                "href": "https://sigma95467.github.io/NextBlog/posts/%E7%AC%94%E8%AE%B0ue4%E5%AE%9E%E6%97%B6%E6%B8%B2%E6%9F%93%E5%9F%BA%E7%A1%80/",
                "title": "[笔记]UE4实时渲染基础",
                "section": "posts",
                "date" : "2022.03.25",
                "body": "课程地址：https://learn.unrealengine.com/\n基础知识 可延展性 在应用程序运行时改变画面渲染效果，提升或者降低帧率等，可使应用移植到不同设备上。\n延迟渲染和前向渲染  游戏大作一般用延迟渲染，手机、VR一般用前向渲染 前向渲染支持MSAA，而延迟渲染只能用TAA（会在画面中看到重影） 延迟渲染需要用到G-Buffer，包含渲染管线后期需要的所有信息  实时渲染性能 CPU渲染：\n 处理场景、应用中的位置、旋转、变换 计算动画、物理效果、碰撞、人工智能 确定程序运行期间对象生成与销毁  GPU渲染：\n 光照、模型自身的渲染、反射、着色器  两种渲染是同时发生的\n像素着色器的开销  每加一层半透明效果就要重新计算像素颜色，每个材质都会添加要与其后像素混合的新图层。 屏幕上需要着色的像素数量。在远处时，屏幕需要着色着色像素较少，开销更小。  场景渲染方式 引擎不会逐像素渲染，而是逐对象渲染，一个接一个模型渲染，逐渐渲染出整幅画面。\n引擎以drawcall为单位进行渲染，渲染开销不取决于多边形数量，而是drawcall的次数，例如彩色低模雕像（有多种材质，每种材质都意味着一次drawcall）的drawcall比高模雕像更多\n动态阴影 动态阴影会随着场景多变形数量增多而产生更大开销，如果使用大量动态光照就需要注意场景中的多边形数量对性能的影响。\n"
            }
    
        ,
            {
                "id": 2,
                "href": "https://sigma95467.github.io/NextBlog/posts/%E7%AC%94%E8%AE%B0ue4%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2%E5%AE%9E%E6%97%B6%E6%B8%B2%E6%9F%93/",
                "title": "[笔记]UE4深度探索实时渲染",
                "section": "posts",
                "date" : "2022.03.25",
                "body": "实时渲染是一个损失性能的过程，你做的每一件事都是一种损耗，我们的目标是想方设法平稳达到目标帧率。\n  所有环节追求尽可能高效（废话\n  严格的流程标准与限制\n先确定资源规格，再基于这些规格设计架构\n  并非所有东西都是即使渲染，而是预渲染和实时渲染结合\n  混合方案\n\n  延迟渲染  每个阶段不会拥有之前阶段的信息 擅长渲染动态光照、提供高质量的渲染画面 可灵活调整渲染结果  前向渲染  光照和着色不会被延迟，在渲染几何体时同时完成 随着功能的增加，屏幕后画面会越来越复杂，不能灵活调整 支持MSAA获得更好的抗锯齿 因为在同一个环节完成，所以有个多信息来支持更灵活的光照 前向渲染更适合渲染半透明  在真正渲染前，就会执行计算，图中30FPS意味着CPU与GPU有66ms延迟，但他们是同步的\n因为实时渲染，观察者会随时做出变化，所以在渲染前我们需要计算对象的具体位置，\n计算动画、模型和对象的位置、物理、AI、spawn、destroy等一切可能影响对象位置的因素\n虽然知道了对象位置，但我们不需要把所有对象都渲染出来，只需要渲染可见内容就行了。大多数工作由CPU完成，GPU也会处理一部分。\n遮挡阶段(Occlusion process)建立一张表记录所有可见对象和模型，逐对象进行遮挡\n执行顺序\n 距离剔除(Distance Culling) 视锥体剔除(Frustum Culling) 可见性预计算(Precomputed Visibility) 遮挡剔除(Occlusion Culling)  "
            }
    
        ,
            {
                "id": 3,
                "href": "https://sigma95467.github.io/NextBlog/posts/dx12%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/",
                "title": "DirectX 12 图形管线",
                "section": "posts",
                "date" : "2022.03.25",
                "body": "DirectX 12 图形管道 DirectX 12 图形管道由几个阶段组成。渲染管道的某些阶段是固定的，这意味着阶段仅通过 DirectX 12 API 的功能进行配置，并且没有“着色程序”。其他阶段是可编程的，可以通过使用“着色程序”进行控制。\n顶点着色器阶段 顶点着色器（VS）阶段负责将顶点数据从对象空间转换到剪辑空间。顶点着色器还可用于执行（骨骼）动画或计算逐顶点光照。顶点着色器将单个顶点作为输入并输出顶点的剪辑空间位置。顶点着色器是定义有效管道状态对象[15]绝对需要的唯一着色器阶段。\nHull Shader (HS) 阶段是一个可选的着色器阶段，负责确定细分阶段 应细分多少输入控制补丁。 镶嵌器阶段 Tessellator 阶段是一个固定功能阶段，它根据外壳着色器阶段 [14] 指定的细分因子将补丁基元细分为更小的基元。\n域着色器阶段 域着色器（DS）阶段是一个可选的着色器阶段，它根据外壳着色器的输出控制点和镶嵌器阶段的插值坐标计算最终的顶点属性[14]。域着色器的输入是来自镶嵌器阶段的单个输出点，输出是镶嵌图元的计算属性。 几何着色器阶段 几何着色器 (GS) 阶段是一个可选的着色器阶段，它采用单个几何图元（点图元的单个顶点、三角形图元的三个顶点和线图元的两个顶点）作为输入，并且可以丢弃图元，将图元转换为另一种图元类型（例如指向四边形的点）或生成其他图元。\n流输出阶段 流输出 (SO) 阶段是一个可选的固定功能阶段，可用于将原始数据反馈到 GPU 内存中。这些数据可以再循环回渲染管线，由另一组着色器处理。这对于在粒子效果中生成或终止粒子很有用。几何着色器可以丢弃应该终止的粒子，或者如果应该产生粒子则生成新粒子。 光栅化阶段\n光栅化阶段 (RS) 阶段是一个固定功能阶段，如果启用正面或背面剔除，它将将图元裁剪到视锥中并执行图元剔除。光栅化阶段还将在每个图元的面上插入每个顶点的属性，并将插入的值传递给像素着色器。 像素着色器阶段 像素着色器 (PS) 阶段从光栅化阶段获取每个顶点的插值值，并产生一个（或多个）每个像素颜色值。像素着色器还可以通过将单个分量 32 位浮点值映射到 SV_Depth 语义来选择性地输出当前像素的深度值，但这不是像素着色器程序的要求。对于图元 覆盖的每个像素，都会调用一次像素着色器。\n产出合并阶段 Output-Merger (OM) 阶段将各种类型的输出数据（像素着色器输出值、深度值和模板信息）与当前绑定的渲染目标的内容组合在一起，以生成最终的管线结果。 GPU 同步 对于刚开始使用 DirectX 12 的程序员来说，更难理解的概念之一是同步。在早期版本的 DirectX 和 OpenGL 中，不需要关注 GPU 同步来让 GPU 渲染某些东西，它通常由驱动程序处理，几乎不需要图形程序员的干预。在 DirectX 12 中，图形程序员必须执行显式 GPU 同步\n"
            }
    
]
